{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environmental detection successful.\n",
      "Torch: 2.2.2\n",
      "OpenCV: 4.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch, cv2, albumentations, sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Environmental detection successful.\")\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"OpenCV:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] First 20 samples loaded:\n",
      "Sample 0: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/66815/frame_000.jpg\n",
      "Sample 1: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/70261/frame_000.jpg\n",
      "Sample 2: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/64065/frame_000.jpg\n",
      "Sample 3: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/64067/frame_000.jpg\n",
      "Sample 4: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/64058/frame_000.jpg\n",
      "Sample 5: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/64060/frame_000.jpg\n",
      "Sample 6: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/64056/frame_000.jpg\n",
      "Sample 7: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/64057/frame_000.jpg\n",
      "Sample 8: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/64068/frame_000.jpg\n",
      "Sample 9: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/64066/frame_000.jpg\n",
      "Sample 10: class=write, label=293\n",
      "    Frame count: 30 | First frame: data/frames/train/write/64059/frame_000.jpg\n",
      "Sample 11: class=your, label=300\n",
      "    Frame count: 30 | First frame: data/frames/train/your/64438/frame_000.jpg\n",
      "Sample 12: class=your, label=300\n",
      "    Frame count: 30 | First frame: data/frames/train/your/64436/frame_000.jpg\n",
      "Sample 13: class=your, label=300\n",
      "    Frame count: 30 | First frame: data/frames/train/your/64430/frame_000.jpg\n",
      "Sample 14: class=your, label=300\n",
      "    Frame count: 30 | First frame: data/frames/train/your/64437/frame_000.jpg\n",
      "Sample 15: class=your, label=300\n",
      "    Frame count: 30 | First frame: data/frames/train/your/64435/frame_000.jpg\n",
      "Sample 16: class=your, label=300\n",
      "    Frame count: 30 | First frame: data/frames/train/your/64433/frame_000.jpg\n",
      "Sample 17: class=your, label=300\n",
      "    Frame count: 30 | First frame: data/frames/train/your/64427/frame_000.jpg\n",
      "Sample 18: class=your, label=300\n",
      "    Frame count: 30 | First frame: data/frames/train/your/64429/frame_000.jpg\n",
      "Sample 19: class=apple, label=8\n",
      "    Frame count: 30 | First frame: data/frames/train/apple/68003/frame_000.jpg\n",
      "train_dir resolved to: /Users/yhhu/Desktop/Part2/code/slr_project/data/frames/train\n"
     ]
    }
   ],
   "source": [
    "import sys, os, importlib\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import importlib\n",
    "importlib.reload(sys.modules['preprocessing.dataset'])\n",
    "\n",
    "from preprocessing.dataset import SignLanguageDataset\n",
    "\n",
    "\n",
    "# Automatically create label_map\n",
    "train_dir = \"data/frames/train\"\n",
    "label_map = {cls_name: idx for idx, cls_name in enumerate(sorted(os.listdir(train_dir)))}\n",
    "\n",
    "\n",
    "dataset = SignLanguageDataset(\n",
    "    root_dir=train_dir,\n",
    "    label_map=label_map,\n",
    "    num_frames=30,\n",
    "    split=\"train\"\n",
    ")\n",
    "print(\"train_dir resolved to:\", os.path.abspath(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slr-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
