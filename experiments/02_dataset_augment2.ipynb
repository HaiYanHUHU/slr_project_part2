{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "from preprocessing.dataset import SignLanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # Whether to support GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category quantity: 300\n",
      "Sample mapping: [('about', 0), ('accident', 1), ('africa', 2), ('again', 3), ('all', 4)]\n"
     ]
    }
   ],
   "source": [
    "# Automatically generate category name -> index mapping\n",
    "frame_root = \"../data/frames/train\"\n",
    "class_names = sorted(os.listdir(frame_root))\n",
    "label_map = {cls: i for i, cls in enumerate(class_names)}\n",
    "print(\"Category quantity:\", len(label_map))\n",
    "print(\"Sample mapping:\", list(label_map.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    # A.RandomCrop(224, 224, scale=(0.8, 1.0), ratio=(0.9, 1.1), p=0.5),  # Random Cropping\n",
    "    A.ColorJitter(brightness=0.02, contrast=0.02, saturation=0.01, hue=0.05, p=0.01), # Jitter\n",
    "\n",
    " \n",
    "    #A.OneOf([\n",
    "        #A.GaussianBlur(blur_limit=3, p=0.3),\n",
    "        #A.MedianBlur(blur_limit=3, p=0.3),\n",
    "        #A.MotionBlur(blur_limit=3, p=0.3),\n",
    "    #], p=0.3), # Nuclear Filter\n",
    "    \n",
    "    #A.CoarseDropout(max_holes=2, max_height=20, max_width=20, fill_value=0, p=0.5),\n",
    "    \n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] First 20 samples loaded:\n",
      "Sample 0: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/66815/frame_000.jpg\n",
      "Sample 1: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/70261/frame_000.jpg\n",
      "Sample 2: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64065/frame_000.jpg\n",
      "Sample 3: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64067/frame_000.jpg\n",
      "Sample 4: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64058/frame_000.jpg\n",
      "Sample 5: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64060/frame_000.jpg\n",
      "Sample 6: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64056/frame_000.jpg\n",
      "Sample 7: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64057/frame_000.jpg\n",
      "Sample 8: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64068/frame_000.jpg\n",
      "Sample 9: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64066/frame_000.jpg\n",
      "Sample 10: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64059/frame_000.jpg\n",
      "Sample 11: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64438/frame_000.jpg\n",
      "Sample 12: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64436/frame_000.jpg\n",
      "Sample 13: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64430/frame_000.jpg\n",
      "Sample 14: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64437/frame_000.jpg\n",
      "Sample 15: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64435/frame_000.jpg\n",
      "Sample 16: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64433/frame_000.jpg\n",
      "Sample 17: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64427/frame_000.jpg\n",
      "Sample 18: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64429/frame_000.jpg\n",
      "Sample 19: class=apple, label=7\n",
      "    Frame count: 20 | First frame: ../data/frames/train/apple/68003/frame_000.jpg\n",
      "Total number of samples: 2488\n"
     ]
    }
   ],
   "source": [
    "dataset = SignLanguageDataset(\n",
    "    root_dir=frame_root,\n",
    "    label_map=label_map,\n",
    "    transform=train_transform,\n",
    "    num_frames=20,\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "print(\"Total number of samples:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of video frames:3, Category index:230\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (224, 224, 20) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     img \u001b[38;5;241m=\u001b[39m video_tensor[i]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# [C, H, W] â†’ [H, W, C]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muint8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnhanced samples (the first 20 frames), category index:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/slr-env/lib/python3.9/site-packages/matplotlib/pyplot.py:3562\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3543\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3560\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3561\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3562\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3571\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m     sci(__ret)\n\u001b[1;32m   3582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m/opt/anaconda3/envs/slr-env/lib/python3.9/site-packages/matplotlib/__init__.py:1476\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1476\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1481\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1482\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1483\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/slr-env/lib/python3.9/site-packages/matplotlib/axes/_axes.py:5895\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5895\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5896\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/slr-env/lib/python3.9/site-packages/matplotlib/image.py:729\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    728\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/slr-env/lib/python3.9/site-packages/matplotlib/image.py:697\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    695\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (224, 224, 20) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_tensor, label = random.choice(dataset)\n",
    "\n",
    "print(f\"Number of video frames:{video_tensor.shape[0]}, Category index:{label}\")\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(20):\n",
    "    img = video_tensor[i].permute(1, 2, 0).cpu().numpy()  # [C, H, W] â†’ [H, W, C]\n",
    "    plt.subplot(2, 10, i + 1)\n",
    "    plt.imshow((img * 255).astype(\"uint8\"))\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(f\"Enhanced samples (the first 20 frames), category index:{label}\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slr-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
