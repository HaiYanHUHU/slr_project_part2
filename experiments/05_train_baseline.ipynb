{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mobilenetv3 import MobileNetV3Extractor\n",
    "from models.lstm_attention import BiLSTMWithAttention\n",
    "from preprocessing.dataset import SignLanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Image preprocessing pipeline: Resize, Normalize, ToTensor\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] label_map:\n",
      "  about: 0\n",
      "  accident: 1\n",
      "  africa: 2\n",
      "  again: 3\n",
      "  all: 4\n",
      "  always: 5\n",
      "  animal: 6\n",
      "  apple: 7\n",
      "  approve: 8\n",
      "  argue: 9\n",
      "  arrive: 10\n",
      "  baby: 11\n",
      "  back: 12\n",
      "  backpack: 13\n",
      "  bad: 14\n",
      "  bake: 15\n",
      "  balance: 16\n",
      "  ball: 17\n",
      "  banana: 18\n",
      "  bar: 19\n",
      "  basketball: 20\n",
      "  bath: 21\n",
      "  bathroom: 22\n",
      "  beard: 23\n",
      "  because: 24\n",
      "  bed: 25\n",
      "  before: 26\n",
      "  behind: 27\n",
      "  bird: 28\n",
      "  birthday: 29\n",
      "  black: 30\n",
      "  blanket: 31\n",
      "  blue: 32\n",
      "  book: 33\n",
      "  bowling: 34\n",
      "  boy: 35\n",
      "  bring: 36\n",
      "  brother: 37\n",
      "  brown: 38\n",
      "  business: 39\n",
      "  but: 40\n",
      "  buy: 41\n",
      "  call: 42\n",
      "  can: 43\n",
      "  candy: 44\n",
      "  careful: 45\n",
      "  cat: 46\n",
      "  catch: 47\n",
      "  center: 48\n",
      "  cereal: 49\n",
      "  chair: 50\n",
      "  champion: 51\n",
      "  change: 52\n",
      "  chat: 53\n",
      "  cheat: 54\n",
      "  check: 55\n",
      "  cheese: 56\n",
      "  children: 57\n",
      "  christmas: 58\n",
      "  city: 59\n",
      "  class: 60\n",
      "  clock: 61\n",
      "  close: 62\n",
      "  clothes: 63\n",
      "  coffee: 64\n",
      "  cold: 65\n",
      "  college: 66\n",
      "  color: 67\n",
      "  computer: 68\n",
      "  convince: 69\n",
      "  cook: 70\n",
      "  cool: 71\n",
      "  copy: 72\n",
      "  corn: 73\n",
      "  cough: 74\n",
      "  country: 75\n",
      "  cousin: 76\n",
      "  cow: 77\n",
      "  crash: 78\n",
      "  crazy: 79\n",
      "  cry: 80\n",
      "  cute: 81\n",
      "  dance: 82\n",
      "  dark: 83\n",
      "  daughter: 84\n",
      "  day: 85\n",
      "  deaf: 86\n",
      "  decide: 87\n",
      "  delay: 88\n",
      "  delicious: 89\n",
      "  different: 90\n",
      "  disappear: 91\n",
      "  discuss: 92\n",
      "  divorce: 93\n",
      "  doctor: 94\n",
      "  dog: 95\n",
      "  door: 96\n",
      "  draw: 97\n",
      "  dress: 98\n",
      "  drink: 99\n",
      "  drive: 100\n",
      "  drop: 101\n",
      "  east: 102\n",
      "  easy: 103\n",
      "  eat: 104\n",
      "  egg: 105\n",
      "  enjoy: 106\n",
      "  environment: 107\n",
      "  example: 108\n",
      "  family: 109\n",
      "  far: 110\n",
      "  fat: 111\n",
      "  father: 112\n",
      "  fault: 113\n",
      "  feel: 114\n",
      "  fine: 115\n",
      "  finish: 116\n",
      "  first: 117\n",
      "  fish: 118\n",
      "  flower: 119\n",
      "  football: 120\n",
      "  forget: 121\n",
      "  friend: 122\n",
      "  friendly: 123\n",
      "  full: 124\n",
      "  future: 125\n",
      "  game: 126\n",
      "  girl: 127\n",
      "  give: 128\n",
      "  glasses: 129\n",
      "  go: 130\n",
      "  good: 131\n",
      "  government: 132\n",
      "  graduate: 133\n",
      "  green: 134\n",
      "  hair: 135\n",
      "  halloween: 136\n",
      "  happy: 137\n",
      "  hard: 138\n",
      "  hat: 139\n",
      "  have: 140\n",
      "  headache: 141\n",
      "  hear: 142\n",
      "  hearing: 143\n",
      "  heart: 144\n",
      "  help: 145\n",
      "  here: 146\n",
      "  home: 147\n",
      "  hope: 148\n",
      "  hot: 149\n",
      "  hour: 150\n",
      "  house: 151\n",
      "  how: 152\n",
      "  humble: 153\n",
      "  hurry: 154\n",
      "  husband: 155\n",
      "  improve: 156\n",
      "  inform: 157\n",
      "  interest: 158\n",
      "  internet: 159\n",
      "  jacket: 160\n",
      "  join: 161\n",
      "  jump: 162\n",
      "  kill: 163\n",
      "  kiss: 164\n",
      "  knife: 165\n",
      "  know: 166\n",
      "  language: 167\n",
      "  last: 168\n",
      "  late: 169\n",
      "  later: 170\n",
      "  laugh: 171\n",
      "  law: 172\n",
      "  learn: 173\n",
      "  leave: 174\n",
      "  letter: 175\n",
      "  light: 176\n",
      "  like: 177\n",
      "  list: 178\n",
      "  live: 179\n",
      "  lose: 180\n",
      "  make: 181\n",
      "  man: 182\n",
      "  many: 183\n",
      "  match: 184\n",
      "  mean: 185\n",
      "  meat: 186\n",
      "  medicine: 187\n",
      "  meet: 188\n",
      "  milk: 189\n",
      "  money: 190\n",
      "  more: 191\n",
      "  most: 192\n",
      "  mother: 193\n",
      "  movie: 194\n",
      "  music: 195\n",
      "  name: 196\n",
      "  need: 197\n",
      "  new: 198\n",
      "  no: 199\n",
      "  none: 200\n",
      "  now: 201\n",
      "  office: 202\n",
      "  old: 203\n",
      "  orange: 204\n",
      "  order: 205\n",
      "  paint: 206\n",
      "  pants: 207\n",
      "  paper: 208\n",
      "  party: 209\n",
      "  past: 210\n",
      "  pencil: 211\n",
      "  person: 212\n",
      "  pink: 213\n",
      "  pizza: 214\n",
      "  plan: 215\n",
      "  play: 216\n",
      "  please: 217\n",
      "  police: 218\n",
      "  practice: 219\n",
      "  president: 220\n",
      "  problem: 221\n",
      "  pull: 222\n",
      "  purple: 223\n",
      "  rabbit: 224\n",
      "  read: 225\n",
      "  red: 226\n",
      "  remember: 227\n",
      "  restaurant: 228\n",
      "  ride: 229\n",
      "  right: 230\n",
      "  room: 231\n",
      "  run: 232\n",
      "  russia: 233\n",
      "  salt: 234\n",
      "  same: 235\n",
      "  sandwich: 236\n",
      "  school: 237\n",
      "  secretary: 238\n",
      "  share: 239\n",
      "  shirt: 240\n",
      "  short: 241\n",
      "  show: 242\n",
      "  sick: 243\n",
      "  sign: 244\n",
      "  since: 245\n",
      "  small: 246\n",
      "  snow: 247\n",
      "  some: 248\n",
      "  son: 249\n",
      "  soon: 250\n",
      "  south: 251\n",
      "  stay: 252\n",
      "  student: 253\n",
      "  study: 254\n",
      "  sunday: 255\n",
      "  table: 256\n",
      "  take: 257\n",
      "  tall: 258\n",
      "  tea: 259\n",
      "  teach: 260\n",
      "  teacher: 261\n",
      "  tell: 262\n",
      "  test: 263\n",
      "  thanksgiving: 264\n",
      "  theory: 265\n",
      "  thin: 266\n",
      "  thursday: 267\n",
      "  time: 268\n",
      "  tired: 269\n",
      "  tomato: 270\n",
      "  trade: 271\n",
      "  train: 272\n",
      "  travel: 273\n",
      "  ugly: 274\n",
      "  visit: 275\n",
      "  wait: 276\n",
      "  walk: 277\n",
      "  want: 278\n",
      "  war: 279\n",
      "  water: 280\n",
      "  week: 281\n",
      "  what: 282\n",
      "  where: 283\n",
      "  white: 284\n",
      "  who: 285\n",
      "  why: 286\n",
      "  wife: 287\n",
      "  window: 288\n",
      "  with: 289\n",
      "  woman: 290\n",
      "  work: 291\n",
      "  write: 292\n",
      "  wrong: 293\n",
      "  year: 294\n",
      "  yellow: 295\n",
      "  yes: 296\n",
      "  yesterday: 297\n",
      "  you: 298\n",
      "  your: 299\n",
      "Discovered category: {'about': 0, 'accident': 1, 'africa': 2, 'again': 3, 'all': 4, 'always': 5, 'animal': 6, 'apple': 7, 'approve': 8, 'argue': 9, 'arrive': 10, 'baby': 11, 'back': 12, 'backpack': 13, 'bad': 14, 'bake': 15, 'balance': 16, 'ball': 17, 'banana': 18, 'bar': 19, 'basketball': 20, 'bath': 21, 'bathroom': 22, 'beard': 23, 'because': 24, 'bed': 25, 'before': 26, 'behind': 27, 'bird': 28, 'birthday': 29, 'black': 30, 'blanket': 31, 'blue': 32, 'book': 33, 'bowling': 34, 'boy': 35, 'bring': 36, 'brother': 37, 'brown': 38, 'business': 39, 'but': 40, 'buy': 41, 'call': 42, 'can': 43, 'candy': 44, 'careful': 45, 'cat': 46, 'catch': 47, 'center': 48, 'cereal': 49, 'chair': 50, 'champion': 51, 'change': 52, 'chat': 53, 'cheat': 54, 'check': 55, 'cheese': 56, 'children': 57, 'christmas': 58, 'city': 59, 'class': 60, 'clock': 61, 'close': 62, 'clothes': 63, 'coffee': 64, 'cold': 65, 'college': 66, 'color': 67, 'computer': 68, 'convince': 69, 'cook': 70, 'cool': 71, 'copy': 72, 'corn': 73, 'cough': 74, 'country': 75, 'cousin': 76, 'cow': 77, 'crash': 78, 'crazy': 79, 'cry': 80, 'cute': 81, 'dance': 82, 'dark': 83, 'daughter': 84, 'day': 85, 'deaf': 86, 'decide': 87, 'delay': 88, 'delicious': 89, 'different': 90, 'disappear': 91, 'discuss': 92, 'divorce': 93, 'doctor': 94, 'dog': 95, 'door': 96, 'draw': 97, 'dress': 98, 'drink': 99, 'drive': 100, 'drop': 101, 'east': 102, 'easy': 103, 'eat': 104, 'egg': 105, 'enjoy': 106, 'environment': 107, 'example': 108, 'family': 109, 'far': 110, 'fat': 111, 'father': 112, 'fault': 113, 'feel': 114, 'fine': 115, 'finish': 116, 'first': 117, 'fish': 118, 'flower': 119, 'football': 120, 'forget': 121, 'friend': 122, 'friendly': 123, 'full': 124, 'future': 125, 'game': 126, 'girl': 127, 'give': 128, 'glasses': 129, 'go': 130, 'good': 131, 'government': 132, 'graduate': 133, 'green': 134, 'hair': 135, 'halloween': 136, 'happy': 137, 'hard': 138, 'hat': 139, 'have': 140, 'headache': 141, 'hear': 142, 'hearing': 143, 'heart': 144, 'help': 145, 'here': 146, 'home': 147, 'hope': 148, 'hot': 149, 'hour': 150, 'house': 151, 'how': 152, 'humble': 153, 'hurry': 154, 'husband': 155, 'improve': 156, 'inform': 157, 'interest': 158, 'internet': 159, 'jacket': 160, 'join': 161, 'jump': 162, 'kill': 163, 'kiss': 164, 'knife': 165, 'know': 166, 'language': 167, 'last': 168, 'late': 169, 'later': 170, 'laugh': 171, 'law': 172, 'learn': 173, 'leave': 174, 'letter': 175, 'light': 176, 'like': 177, 'list': 178, 'live': 179, 'lose': 180, 'make': 181, 'man': 182, 'many': 183, 'match': 184, 'mean': 185, 'meat': 186, 'medicine': 187, 'meet': 188, 'milk': 189, 'money': 190, 'more': 191, 'most': 192, 'mother': 193, 'movie': 194, 'music': 195, 'name': 196, 'need': 197, 'new': 198, 'no': 199, 'none': 200, 'now': 201, 'office': 202, 'old': 203, 'orange': 204, 'order': 205, 'paint': 206, 'pants': 207, 'paper': 208, 'party': 209, 'past': 210, 'pencil': 211, 'person': 212, 'pink': 213, 'pizza': 214, 'plan': 215, 'play': 216, 'please': 217, 'police': 218, 'practice': 219, 'president': 220, 'problem': 221, 'pull': 222, 'purple': 223, 'rabbit': 224, 'read': 225, 'red': 226, 'remember': 227, 'restaurant': 228, 'ride': 229, 'right': 230, 'room': 231, 'run': 232, 'russia': 233, 'salt': 234, 'same': 235, 'sandwich': 236, 'school': 237, 'secretary': 238, 'share': 239, 'shirt': 240, 'short': 241, 'show': 242, 'sick': 243, 'sign': 244, 'since': 245, 'small': 246, 'snow': 247, 'some': 248, 'son': 249, 'soon': 250, 'south': 251, 'stay': 252, 'student': 253, 'study': 254, 'sunday': 255, 'table': 256, 'take': 257, 'tall': 258, 'tea': 259, 'teach': 260, 'teacher': 261, 'tell': 262, 'test': 263, 'thanksgiving': 264, 'theory': 265, 'thin': 266, 'thursday': 267, 'time': 268, 'tired': 269, 'tomato': 270, 'trade': 271, 'train': 272, 'travel': 273, 'ugly': 274, 'visit': 275, 'wait': 276, 'walk': 277, 'want': 278, 'war': 279, 'water': 280, 'week': 281, 'what': 282, 'where': 283, 'white': 284, 'who': 285, 'why': 286, 'wife': 287, 'window': 288, 'with': 289, 'woman': 290, 'work': 291, 'write': 292, 'wrong': 293, 'year': 294, 'yellow': 295, 'yes': 296, 'yesterday': 297, 'you': 298, 'your': 299}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] First 20 samples loaded:\n",
      "Sample 0: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/66815/frame_000.jpg\n",
      "Sample 1: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/70261/frame_000.jpg\n",
      "Sample 2: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64065/frame_000.jpg\n",
      "Sample 3: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64067/frame_000.jpg\n",
      "Sample 4: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64058/frame_000.jpg\n",
      "Sample 5: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64060/frame_000.jpg\n",
      "Sample 6: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64056/frame_000.jpg\n",
      "Sample 7: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64057/frame_000.jpg\n",
      "Sample 8: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64068/frame_000.jpg\n",
      "Sample 9: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64066/frame_000.jpg\n",
      "Sample 10: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64059/frame_000.jpg\n",
      "Sample 11: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64438/frame_000.jpg\n",
      "Sample 12: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64436/frame_000.jpg\n",
      "Sample 13: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64430/frame_000.jpg\n",
      "Sample 14: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64437/frame_000.jpg\n",
      "Sample 15: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64435/frame_000.jpg\n",
      "Sample 16: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64433/frame_000.jpg\n",
      "Sample 17: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64427/frame_000.jpg\n",
      "Sample 18: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64429/frame_000.jpg\n",
      "Sample 19: class=apple, label=7\n",
      "    Frame count: 20 | First frame: ../data/frames/train/apple/68003/frame_000.jpg\n"
     ]
    }
   ],
   "source": [
    "# Automatically obtain all category names and map them to digital labels\n",
    "train_root = \"../data/frames/train\"\n",
    "# class_names = sorted(os.listdir(train_root))  \n",
    "class_names = sorted([\n",
    "    d for d in os.listdir(train_root)\n",
    "    if os.path.isdir(os.path.join(train_root, d)) and not d.startswith(\".\")\n",
    "]) \n",
    "\n",
    "# Name\n",
    "label_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "print(\"[DEBUG] label_map:\")\n",
    "for name, idx in label_map.items():\n",
    "    print(f\"  {name}: {idx}\")\n",
    "    \n",
    "print(\"Discovered category:\", label_map)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = SignLanguageDataset(\n",
    "    root_dir=train_root,\n",
    "    label_map=label_map,\n",
    "    num_frames=20,\n",
    "    split=\"train\",\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSLRModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = MobileNetV3Extractor()\n",
    "        self.temporal_model = BiLSTMWithAttention(\n",
    "            input_dim=960, hidden_dim=256, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):  # x: [B, T, C, H, W]\n",
    "        features = self.feature_extractor(x)          # [B, T, 960]\n",
    "        logits, _ = self.temporal_model(features)     # [B, num_classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FullSLRModel(num_classes=len(label_map)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 328/1244 [11:57:37<5:15:03, 20.64s/it]   "
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for videos, labels in tqdm(train_loader):\n",
    "       \n",
    "        # videos = videos.permute(0, 2, 1, 3, 4) # [B, C, T, H, W] → [B, T, C, H, W]\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(videos)  # [B, num_classes]\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to: ../checkpoints/baseline_epoch1.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = f\"../checkpoints/baseline_epoch{epoch+1}.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"model saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slr-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
