{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mobilenetv3 import MobileNetV3Extractor\n",
    "from models.lstm_attention import BiLSTMWithAttention\n",
    "from preprocessing.dataset import SignLanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Image preprocessing pipeline: Resize, Normalize, ToTensor\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered category: {'about': 0, 'accident': 1, 'africa': 2, 'again': 3, 'all': 4, 'always': 5, 'animal': 6, 'apple': 7, 'approve': 8, 'argue': 9, 'arrive': 10, 'baby': 11, 'back': 12, 'backpack': 13, 'bad': 14, 'bake': 15, 'balance': 16, 'ball': 17, 'banana': 18, 'bar': 19, 'basketball': 20, 'bath': 21, 'bathroom': 22, 'beard': 23, 'because': 24, 'bed': 25, 'before': 26, 'behind': 27, 'bird': 28, 'birthday': 29, 'black': 30, 'blanket': 31, 'blue': 32, 'book': 33, 'bowling': 34, 'boy': 35, 'bring': 36, 'brother': 37, 'brown': 38, 'business': 39, 'but': 40, 'buy': 41, 'call': 42, 'can': 43, 'candy': 44, 'careful': 45, 'cat': 46, 'catch': 47, 'center': 48, 'cereal': 49, 'chair': 50, 'champion': 51, 'change': 52, 'chat': 53, 'cheat': 54, 'check': 55, 'cheese': 56, 'children': 57, 'christmas': 58, 'city': 59, 'class': 60, 'clock': 61, 'close': 62, 'clothes': 63, 'coffee': 64, 'cold': 65, 'college': 66, 'color': 67, 'computer': 68, 'convince': 69, 'cook': 70, 'cool': 71, 'copy': 72, 'corn': 73, 'cough': 74, 'country': 75, 'cousin': 76, 'cow': 77, 'crash': 78, 'crazy': 79, 'cry': 80, 'cute': 81, 'dance': 82, 'dark': 83, 'daughter': 84, 'day': 85, 'deaf': 86, 'decide': 87, 'delay': 88, 'delicious': 89, 'different': 90, 'disappear': 91, 'discuss': 92, 'divorce': 93, 'doctor': 94, 'dog': 95, 'door': 96, 'draw': 97, 'dress': 98, 'drink': 99, 'drive': 100, 'drop': 101, 'east': 102, 'easy': 103, 'eat': 104, 'egg': 105, 'enjoy': 106, 'environment': 107, 'example': 108, 'family': 109, 'far': 110, 'fat': 111, 'father': 112, 'fault': 113, 'feel': 114, 'fine': 115, 'finish': 116, 'first': 117, 'fish': 118, 'flower': 119, 'football': 120, 'forget': 121, 'friend': 122, 'friendly': 123, 'full': 124, 'future': 125, 'game': 126, 'girl': 127, 'give': 128, 'glasses': 129, 'go': 130, 'good': 131, 'government': 132, 'graduate': 133, 'green': 134, 'hair': 135, 'halloween': 136, 'happy': 137, 'hard': 138, 'hat': 139, 'have': 140, 'headache': 141, 'hear': 142, 'hearing': 143, 'heart': 144, 'help': 145, 'here': 146, 'home': 147, 'hope': 148, 'hot': 149, 'hour': 150, 'house': 151, 'how': 152, 'humble': 153, 'hurry': 154, 'husband': 155, 'improve': 156, 'inform': 157, 'interest': 158, 'internet': 159, 'jacket': 160, 'join': 161, 'jump': 162, 'kill': 163, 'kiss': 164, 'knife': 165, 'know': 166, 'language': 167, 'last': 168, 'late': 169, 'later': 170, 'laugh': 171, 'law': 172, 'learn': 173, 'leave': 174, 'letter': 175, 'light': 176, 'like': 177, 'list': 178, 'live': 179, 'lose': 180, 'make': 181, 'man': 182, 'many': 183, 'match': 184, 'mean': 185, 'meat': 186, 'medicine': 187, 'meet': 188, 'milk': 189, 'money': 190, 'more': 191, 'most': 192, 'mother': 193, 'movie': 194, 'music': 195, 'name': 196, 'need': 197, 'new': 198, 'no': 199, 'none': 200, 'now': 201, 'office': 202, 'old': 203, 'orange': 204, 'order': 205, 'paint': 206, 'pants': 207, 'paper': 208, 'party': 209, 'past': 210, 'pencil': 211, 'person': 212, 'pink': 213, 'pizza': 214, 'plan': 215, 'play': 216, 'please': 217, 'police': 218, 'practice': 219, 'president': 220, 'problem': 221, 'pull': 222, 'purple': 223, 'rabbit': 224, 'read': 225, 'red': 226, 'remember': 227, 'restaurant': 228, 'ride': 229, 'right': 230, 'room': 231, 'run': 232, 'russia': 233, 'salt': 234, 'same': 235, 'sandwich': 236, 'school': 237, 'secretary': 238, 'share': 239, 'shirt': 240, 'short': 241, 'show': 242, 'sick': 243, 'sign': 244, 'since': 245, 'small': 246, 'snow': 247, 'some': 248, 'son': 249, 'soon': 250, 'south': 251, 'stay': 252, 'student': 253, 'study': 254, 'sunday': 255, 'table': 256, 'take': 257, 'tall': 258, 'tea': 259, 'teach': 260, 'teacher': 261, 'tell': 262, 'test': 263, 'thanksgiving': 264, 'theory': 265, 'thin': 266, 'thursday': 267, 'time': 268, 'tired': 269, 'tomato': 270, 'trade': 271, 'train': 272, 'travel': 273, 'ugly': 274, 'visit': 275, 'wait': 276, 'walk': 277, 'want': 278, 'war': 279, 'water': 280, 'week': 281, 'what': 282, 'where': 283, 'white': 284, 'who': 285, 'why': 286, 'wife': 287, 'window': 288, 'with': 289, 'woman': 290, 'work': 291, 'write': 292, 'wrong': 293, 'year': 294, 'yellow': 295, 'yes': 296, 'yesterday': 297, 'you': 298, 'your': 299}\n",
      "\n",
      "[DEBUG] First 20 samples loaded:\n",
      "Sample 0: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/66815/frame_000.jpg\n",
      "Sample 1: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/70261/frame_000.jpg\n",
      "Sample 2: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64065/frame_000.jpg\n",
      "Sample 3: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64067/frame_000.jpg\n",
      "Sample 4: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64058/frame_000.jpg\n",
      "Sample 5: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64060/frame_000.jpg\n",
      "Sample 6: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64056/frame_000.jpg\n",
      "Sample 7: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64057/frame_000.jpg\n",
      "Sample 8: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64068/frame_000.jpg\n",
      "Sample 9: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64066/frame_000.jpg\n",
      "Sample 10: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64059/frame_000.jpg\n",
      "Sample 11: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64438/frame_000.jpg\n",
      "Sample 12: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64436/frame_000.jpg\n",
      "Sample 13: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64430/frame_000.jpg\n",
      "Sample 14: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64437/frame_000.jpg\n",
      "Sample 15: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64435/frame_000.jpg\n",
      "Sample 16: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64433/frame_000.jpg\n",
      "Sample 17: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64427/frame_000.jpg\n",
      "Sample 18: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64429/frame_000.jpg\n",
      "Sample 19: class=apple, label=7\n",
      "    Frame count: 20 | First frame: ../data/frames/train/apple/68003/frame_000.jpg\n"
     ]
    }
   ],
   "source": [
    "# Automatically obtain all category names and map them to digital labels\n",
    "train_root = \"../data/frames/train\"\n",
    "class_names = sorted(os.listdir(train_root))  \n",
    "# Name\n",
    "label_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "print(\"Discovered category:\", label_map)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = SignLanguageDataset(\n",
    "    root_dir=train_root,\n",
    "    label_map=label_map,\n",
    "    num_frames=20,\n",
    "    split=\"train\",\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSLRModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = MobileNetV3Extractor()\n",
    "        self.temporal_model = BiLSTMWithAttention(\n",
    "            input_dim=960, hidden_dim=256, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):  # x: [B, T, C, H, W]\n",
    "        features = self.feature_extractor(x)          # [B, T, 960]\n",
    "        logits, _ = self.temporal_model(features)     # [B, num_classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FullSLRModel(num_classes=len(label_map)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/622 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 622/622 [13:11:02<00:00, 76.31s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1] | Loss: 5.7179 | Acc: 0.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for videos, labels in tqdm(train_loader):\n",
    "        # videos = videos.permute(0, 2, 1, 3, 4) # [B, C, T, H, W] → [B, T, C, H, W]\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(videos)  # [B, num_classes]\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to: ../checkpoints/baseline_epoch1.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = f\"../checkpoints/baseline_epoch{epoch+1}.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"model saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slr-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
