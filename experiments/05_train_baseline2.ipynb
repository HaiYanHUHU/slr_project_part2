{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mobilenetv3 import MobileNetV3Extractor\n",
    "from models.lstm_attention import BiLSTMWithAttention\n",
    "from preprocessing.dataset import SignLanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Image preprocessing pipeline: Resize, Normalize, ToTensor\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered category: {'.DS_Store': 0, 'about': 1, 'accident': 2, 'africa': 3, 'again': 4, 'all': 5, 'always': 6, 'animal': 7, 'apple': 8, 'approve': 9, 'argue': 10, 'arrive': 11, 'baby': 12, 'back': 13, 'backpack': 14, 'bad': 15, 'bake': 16, 'balance': 17, 'ball': 18, 'banana': 19, 'bar': 20, 'basketball': 21, 'bath': 22, 'bathroom': 23, 'beard': 24, 'because': 25, 'bed': 26, 'before': 27, 'behind': 28, 'bird': 29, 'birthday': 30, 'black': 31, 'blanket': 32, 'blue': 33, 'book': 34, 'bowling': 35, 'boy': 36, 'bring': 37, 'brother': 38, 'brown': 39, 'business': 40, 'but': 41, 'buy': 42, 'call': 43, 'can': 44, 'candy': 45, 'careful': 46, 'cat': 47, 'catch': 48, 'center': 49, 'cereal': 50, 'chair': 51, 'champion': 52, 'change': 53, 'chat': 54, 'cheat': 55, 'check': 56, 'cheese': 57, 'children': 58, 'christmas': 59, 'city': 60, 'class': 61, 'clock': 62, 'close': 63, 'clothes': 64, 'coffee': 65, 'cold': 66, 'college': 67, 'color': 68, 'computer': 69, 'convince': 70, 'cook': 71, 'cool': 72, 'copy': 73, 'corn': 74, 'cough': 75, 'country': 76, 'cousin': 77, 'cow': 78, 'crash': 79, 'crazy': 80, 'cry': 81, 'cute': 82, 'dance': 83, 'dark': 84, 'daughter': 85, 'day': 86, 'deaf': 87, 'decide': 88, 'delay': 89, 'delicious': 90, 'different': 91, 'disappear': 92, 'discuss': 93, 'divorce': 94, 'doctor': 95, 'dog': 96, 'door': 97, 'draw': 98, 'dress': 99, 'drink': 100, 'drive': 101, 'drop': 102, 'east': 103, 'easy': 104, 'eat': 105, 'egg': 106, 'enjoy': 107, 'environment': 108, 'example': 109, 'family': 110, 'far': 111, 'fat': 112, 'father': 113, 'fault': 114, 'feel': 115, 'fine': 116, 'finish': 117, 'first': 118, 'fish': 119, 'flower': 120, 'football': 121, 'forget': 122, 'friend': 123, 'friendly': 124, 'full': 125, 'future': 126, 'game': 127, 'girl': 128, 'give': 129, 'glasses': 130, 'go': 131, 'good': 132, 'government': 133, 'graduate': 134, 'green': 135, 'hair': 136, 'halloween': 137, 'happy': 138, 'hard': 139, 'hat': 140, 'have': 141, 'headache': 142, 'hear': 143, 'hearing': 144, 'heart': 145, 'help': 146, 'here': 147, 'home': 148, 'hope': 149, 'hot': 150, 'hour': 151, 'house': 152, 'how': 153, 'humble': 154, 'hurry': 155, 'husband': 156, 'improve': 157, 'inform': 158, 'interest': 159, 'internet': 160, 'jacket': 161, 'join': 162, 'jump': 163, 'kill': 164, 'kiss': 165, 'knife': 166, 'know': 167, 'language': 168, 'last': 169, 'late': 170, 'later': 171, 'laugh': 172, 'law': 173, 'learn': 174, 'leave': 175, 'letter': 176, 'light': 177, 'like': 178, 'list': 179, 'live': 180, 'lose': 181, 'make': 182, 'man': 183, 'many': 184, 'match': 185, 'mean': 186, 'meat': 187, 'medicine': 188, 'meet': 189, 'milk': 190, 'money': 191, 'more': 192, 'most': 193, 'mother': 194, 'movie': 195, 'music': 196, 'name': 197, 'need': 198, 'new': 199, 'no': 200, 'none': 201, 'now': 202, 'office': 203, 'old': 204, 'orange': 205, 'order': 206, 'paint': 207, 'pants': 208, 'paper': 209, 'party': 210, 'past': 211, 'pencil': 212, 'person': 213, 'pink': 214, 'pizza': 215, 'plan': 216, 'play': 217, 'please': 218, 'police': 219, 'practice': 220, 'president': 221, 'problem': 222, 'pull': 223, 'purple': 224, 'rabbit': 225, 'read': 226, 'red': 227, 'remember': 228, 'restaurant': 229, 'ride': 230, 'right': 231, 'room': 232, 'run': 233, 'russia': 234, 'salt': 235, 'same': 236, 'sandwich': 237, 'school': 238, 'secretary': 239, 'share': 240, 'shirt': 241, 'short': 242, 'show': 243, 'sick': 244, 'sign': 245, 'since': 246, 'small': 247, 'snow': 248, 'some': 249, 'son': 250, 'soon': 251, 'south': 252, 'stay': 253, 'student': 254, 'study': 255, 'sunday': 256, 'table': 257, 'take': 258, 'tall': 259, 'tea': 260, 'teach': 261, 'teacher': 262, 'tell': 263, 'test': 264, 'thanksgiving': 265, 'theory': 266, 'thin': 267, 'thursday': 268, 'time': 269, 'tired': 270, 'tomato': 271, 'trade': 272, 'train': 273, 'travel': 274, 'ugly': 275, 'visit': 276, 'wait': 277, 'walk': 278, 'want': 279, 'war': 280, 'water': 281, 'week': 282, 'what': 283, 'where': 284, 'white': 285, 'who': 286, 'why': 287, 'wife': 288, 'window': 289, 'with': 290, 'woman': 291, 'work': 292, 'write': 293, 'wrong': 294, 'year': 295, 'yellow': 296, 'yes': 297, 'yesterday': 298, 'you': 299, 'your': 300}\n"
     ]
    }
   ],
   "source": [
    "# Automatically obtain all category names and map them to digital labels\n",
    "train_root = \"../data/frames/train\"\n",
    "class_names = sorted(os.listdir(train_root))  \n",
    "# Name\n",
    "label_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "print(\"Discovered category:\", label_map)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = SignLanguageDataset(\n",
    "    root_dir=train_root,\n",
    "    label_map=label_map,\n",
    "    num_frames=30,\n",
    "    split=\"train\",\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSLRModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = MobileNetV3Extractor()\n",
    "        self.temporal_model = BiLSTMWithAttention(\n",
    "            input_dim=960, hidden_dim=256, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):  # x: [B, T, C, H, W]\n",
    "        features = self.feature_extractor(x)          # [B, T, 960]\n",
    "        logits, _ = self.temporal_model(features)     # [B, num_classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/slr-env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/slr-env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FullSLRModel(num_classes=len(label_map)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 622/622 [3:23:11<00:00, 19.60s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2] | Loss: 5.7166 | Acc: 0.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 622/622 [11:51:21<00:00, 68.62s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2] | Loss: 5.5823 | Acc: 0.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for videos, labels in tqdm(train_loader):\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(videos)  # [B, num_classes]\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to: ../checkpoints/baseline_epoch2.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = f\"../checkpoints/baseline_epoch{epoch+1}.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"model saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slr-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
