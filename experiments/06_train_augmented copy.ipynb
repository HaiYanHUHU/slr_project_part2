{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))  \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mobilenetv3 import MobileNetV3Extractor\n",
    "from models.lstm_attention import BiLSTMWithAttention\n",
    "from preprocessing.dataset import SignLanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    # resize to the standard input size\n",
    "    A.Resize(224, 224),  \n",
    "    # A.RandomCrop(200, 200),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    #A.Cutout(num_holes=2, max_h_size=40, max_w_size=40, fill_value=0),\n",
    "     # resize it back to 224 to prevent inconsistent dimensions after enhancement\n",
    "    A.Resize(224, 224), \n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] label_map:\n",
      "  about: 0\n",
      "  accident: 1\n",
      "  africa: 2\n",
      "  again: 3\n",
      "  all: 4\n",
      "  always: 5\n",
      "  animal: 6\n",
      "  apple: 7\n",
      "  approve: 8\n",
      "  argue: 9\n",
      "  arrive: 10\n",
      "  baby: 11\n",
      "  back: 12\n",
      "  backpack: 13\n",
      "  bad: 14\n",
      "  bake: 15\n",
      "  balance: 16\n",
      "  ball: 17\n",
      "  banana: 18\n",
      "  bar: 19\n",
      "  basketball: 20\n",
      "  bath: 21\n",
      "  bathroom: 22\n",
      "  beard: 23\n",
      "  because: 24\n",
      "  bed: 25\n",
      "  before: 26\n",
      "  behind: 27\n",
      "  bird: 28\n",
      "  birthday: 29\n",
      "  black: 30\n",
      "  blanket: 31\n",
      "  blue: 32\n",
      "  book: 33\n",
      "  bowling: 34\n",
      "  boy: 35\n",
      "  bring: 36\n",
      "  brother: 37\n",
      "  brown: 38\n",
      "  business: 39\n",
      "  but: 40\n",
      "  buy: 41\n",
      "  call: 42\n",
      "  can: 43\n",
      "  candy: 44\n",
      "  careful: 45\n",
      "  cat: 46\n",
      "  catch: 47\n",
      "  center: 48\n",
      "  cereal: 49\n",
      "  chair: 50\n",
      "  champion: 51\n",
      "  change: 52\n",
      "  chat: 53\n",
      "  cheat: 54\n",
      "  check: 55\n",
      "  cheese: 56\n",
      "  children: 57\n",
      "  christmas: 58\n",
      "  city: 59\n",
      "  class: 60\n",
      "  clock: 61\n",
      "  close: 62\n",
      "  clothes: 63\n",
      "  coffee: 64\n",
      "  cold: 65\n",
      "  college: 66\n",
      "  color: 67\n",
      "  computer: 68\n",
      "  convince: 69\n",
      "  cook: 70\n",
      "  cool: 71\n",
      "  copy: 72\n",
      "  corn: 73\n",
      "  cough: 74\n",
      "  country: 75\n",
      "  cousin: 76\n",
      "  cow: 77\n",
      "  crash: 78\n",
      "  crazy: 79\n",
      "  cry: 80\n",
      "  cute: 81\n",
      "  dance: 82\n",
      "  dark: 83\n",
      "  daughter: 84\n",
      "  day: 85\n",
      "  deaf: 86\n",
      "  decide: 87\n",
      "  delay: 88\n",
      "  delicious: 89\n",
      "  different: 90\n",
      "  disappear: 91\n",
      "  discuss: 92\n",
      "  divorce: 93\n",
      "  doctor: 94\n",
      "  dog: 95\n",
      "  door: 96\n",
      "  draw: 97\n",
      "  dress: 98\n",
      "  drink: 99\n",
      "  drive: 100\n",
      "  drop: 101\n",
      "  east: 102\n",
      "  easy: 103\n",
      "  eat: 104\n",
      "  egg: 105\n",
      "  enjoy: 106\n",
      "  environment: 107\n",
      "  example: 108\n",
      "  family: 109\n",
      "  far: 110\n",
      "  fat: 111\n",
      "  father: 112\n",
      "  fault: 113\n",
      "  feel: 114\n",
      "  fine: 115\n",
      "  finish: 116\n",
      "  first: 117\n",
      "  fish: 118\n",
      "  flower: 119\n",
      "  football: 120\n",
      "  forget: 121\n",
      "  friend: 122\n",
      "  friendly: 123\n",
      "  full: 124\n",
      "  future: 125\n",
      "  game: 126\n",
      "  girl: 127\n",
      "  give: 128\n",
      "  glasses: 129\n",
      "  go: 130\n",
      "  good: 131\n",
      "  government: 132\n",
      "  graduate: 133\n",
      "  green: 134\n",
      "  hair: 135\n",
      "  halloween: 136\n",
      "  happy: 137\n",
      "  hard: 138\n",
      "  hat: 139\n",
      "  have: 140\n",
      "  headache: 141\n",
      "  hear: 142\n",
      "  hearing: 143\n",
      "  heart: 144\n",
      "  help: 145\n",
      "  here: 146\n",
      "  home: 147\n",
      "  hope: 148\n",
      "  hot: 149\n",
      "  hour: 150\n",
      "  house: 151\n",
      "  how: 152\n",
      "  humble: 153\n",
      "  hurry: 154\n",
      "  husband: 155\n",
      "  improve: 156\n",
      "  inform: 157\n",
      "  interest: 158\n",
      "  internet: 159\n",
      "  jacket: 160\n",
      "  join: 161\n",
      "  jump: 162\n",
      "  kill: 163\n",
      "  kiss: 164\n",
      "  knife: 165\n",
      "  know: 166\n",
      "  language: 167\n",
      "  last: 168\n",
      "  late: 169\n",
      "  later: 170\n",
      "  laugh: 171\n",
      "  law: 172\n",
      "  learn: 173\n",
      "  leave: 174\n",
      "  letter: 175\n",
      "  light: 176\n",
      "  like: 177\n",
      "  list: 178\n",
      "  live: 179\n",
      "  lose: 180\n",
      "  make: 181\n",
      "  man: 182\n",
      "  many: 183\n",
      "  match: 184\n",
      "  mean: 185\n",
      "  meat: 186\n",
      "  medicine: 187\n",
      "  meet: 188\n",
      "  milk: 189\n",
      "  money: 190\n",
      "  more: 191\n",
      "  most: 192\n",
      "  mother: 193\n",
      "  movie: 194\n",
      "  music: 195\n",
      "  name: 196\n",
      "  need: 197\n",
      "  new: 198\n",
      "  no: 199\n",
      "  none: 200\n",
      "  now: 201\n",
      "  office: 202\n",
      "  old: 203\n",
      "  orange: 204\n",
      "  order: 205\n",
      "  paint: 206\n",
      "  pants: 207\n",
      "  paper: 208\n",
      "  party: 209\n",
      "  past: 210\n",
      "  pencil: 211\n",
      "  person: 212\n",
      "  pink: 213\n",
      "  pizza: 214\n",
      "  plan: 215\n",
      "  play: 216\n",
      "  please: 217\n",
      "  police: 218\n",
      "  practice: 219\n",
      "  president: 220\n",
      "  problem: 221\n",
      "  pull: 222\n",
      "  purple: 223\n",
      "  rabbit: 224\n",
      "  read: 225\n",
      "  red: 226\n",
      "  remember: 227\n",
      "  restaurant: 228\n",
      "  ride: 229\n",
      "  right: 230\n",
      "  room: 231\n",
      "  run: 232\n",
      "  russia: 233\n",
      "  salt: 234\n",
      "  same: 235\n",
      "  sandwich: 236\n",
      "  school: 237\n",
      "  secretary: 238\n",
      "  share: 239\n",
      "  shirt: 240\n",
      "  short: 241\n",
      "  show: 242\n",
      "  sick: 243\n",
      "  sign: 244\n",
      "  since: 245\n",
      "  small: 246\n",
      "  snow: 247\n",
      "  some: 248\n",
      "  son: 249\n",
      "  soon: 250\n",
      "  south: 251\n",
      "  stay: 252\n",
      "  student: 253\n",
      "  study: 254\n",
      "  sunday: 255\n",
      "  table: 256\n",
      "  take: 257\n",
      "  tall: 258\n",
      "  tea: 259\n",
      "  teach: 260\n",
      "  teacher: 261\n",
      "  tell: 262\n",
      "  test: 263\n",
      "  thanksgiving: 264\n",
      "  theory: 265\n",
      "  thin: 266\n",
      "  thursday: 267\n",
      "  time: 268\n",
      "  tired: 269\n",
      "  tomato: 270\n",
      "  trade: 271\n",
      "  train: 272\n",
      "  travel: 273\n",
      "  ugly: 274\n",
      "  visit: 275\n",
      "  wait: 276\n",
      "  walk: 277\n",
      "  want: 278\n",
      "  war: 279\n",
      "  water: 280\n",
      "  week: 281\n",
      "  what: 282\n",
      "  where: 283\n",
      "  white: 284\n",
      "  who: 285\n",
      "  why: 286\n",
      "  wife: 287\n",
      "  window: 288\n",
      "  with: 289\n",
      "  woman: 290\n",
      "  work: 291\n",
      "  write: 292\n",
      "  wrong: 293\n",
      "  year: 294\n",
      "  yellow: 295\n",
      "  yes: 296\n",
      "  yesterday: 297\n",
      "  you: 298\n",
      "  your: 299\n",
      "\n",
      "[DEBUG] First 20 samples loaded:\n",
      "Sample 0: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/66815/frame_000.jpg\n",
      "Sample 1: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/70261/frame_000.jpg\n",
      "Sample 2: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64065/frame_000.jpg\n",
      "Sample 3: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64067/frame_000.jpg\n",
      "Sample 4: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64058/frame_000.jpg\n",
      "Sample 5: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64060/frame_000.jpg\n",
      "Sample 6: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64056/frame_000.jpg\n",
      "Sample 7: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64057/frame_000.jpg\n",
      "Sample 8: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64068/frame_000.jpg\n",
      "Sample 9: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64066/frame_000.jpg\n",
      "Sample 10: class=write, label=292\n",
      "    Frame count: 20 | First frame: ../data/frames/train/write/64059/frame_000.jpg\n",
      "Sample 11: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64438/frame_000.jpg\n",
      "Sample 12: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64436/frame_000.jpg\n",
      "Sample 13: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64430/frame_000.jpg\n",
      "Sample 14: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64437/frame_000.jpg\n",
      "Sample 15: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64435/frame_000.jpg\n",
      "Sample 16: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64433/frame_000.jpg\n",
      "Sample 17: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64427/frame_000.jpg\n",
      "Sample 18: class=your, label=299\n",
      "    Frame count: 20 | First frame: ../data/frames/train/your/64429/frame_000.jpg\n",
      "Sample 19: class=apple, label=7\n",
      "    Frame count: 20 | First frame: ../data/frames/train/apple/68003/frame_000.jpg\n"
     ]
    }
   ],
   "source": [
    "train_root = \"../data/frames/train\"\n",
    "# class_names = sorted(os.listdir(train_root))\n",
    "class_names = sorted([\n",
    "    d for d in os.listdir(train_root)\n",
    "    if os.path.isdir(os.path.join(train_root, d)) and not d.startswith(\".\")\n",
    "])\n",
    "\n",
    "label_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "print(\"[DEBUG] label_map:\")\n",
    "for name, idx in label_map.items():\n",
    "    print(f\"  {name}: {idx}\")\n",
    "\n",
    "train_dataset = SignLanguageDataset(\n",
    "    root_dir=train_root,\n",
    "    label_map=label_map,\n",
    "    num_frames=20,\n",
    "    split=\"train\",\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSLRModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = MobileNetV3Extractor()\n",
    "        self.temporal_model = BiLSTMWithAttention(\n",
    "            input_dim=960, hidden_dim=256, num_classes=num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B, T, C, H, W]\n",
    "        features = self.feature_extractor(x)          # [B, T, 960]\n",
    "        logits, _ = self.temporal_model(features)     # [B, num_classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/slr-env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/slr-env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FullSLRModel(num_classes=len(label_map)).to(device)\n",
    "\n",
    "# Label smoothing is helpful for generalization and reduces overfitting\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/622 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "labels.shape: torch.Size([4])\n",
      "labels example: tensor(16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/622 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     30\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m---> 31\u001b[0m epoch_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m100.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcorrect\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for videos, labels in tqdm(train_loader):\n",
    "        \n",
    "        print(torch.bincount(labels))\n",
    "        print(\"labels.shape:\", labels.shape)\n",
    "        print(\"labels example:\", labels[0])\n",
    "        break\n",
    "        # videos = videos.permute(0, 2, 1, 3, 4)  # [B, C, T, H, W] → [B, T, C, H, W]\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(videos)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../checkpoints\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"../checkpoints/mobilenetv3_lstm_aug_smooth.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slr-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
